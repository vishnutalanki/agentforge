from agentforge.tool.llm import llm
import openai

class openai_llm(llm):
    """Concrete implementation of LLM for OpenAI models."""

    def __init__(self, tool_id: str, api_key: str, model: str = "gpt-4"):
        """
        Initialize the OpenAI LLM tool.

        Args:
            tool_id (str): Unique identifier for the tool.
            api_key (str): OpenAI API key for authentication.
            model (str): Model name to use (default: "gpt-4").
        """
        super().__init__(tool_id, model)
        self.api_key = api_key
        openai.api_key = self.api_key

    def execute(self, message: str = "") -> str:
        """
        Use the OpenAI LLM to process the input data and return the response.

        Args:
            input_data (str): The prompt or query for the LLM (default: empty string).

        Returns:
            str: The response generated by the LLM.
        """
        try:
            response = openai.ChatCompletion.create(
                model=self.model,
                message =  {"role": "user", "content": message}
            )
            return response['choices'][0]['message']['content'].strip()
        except Exception as e:
            return f"Error: {str(e)}"

# Example usage
if __name__ == "__main__":
    OpenAI = openai_llm(tool_id="openai_gpt4", api_key="your-api-key")
    result = OpenAI.execute()
    print(result)
    print(OpenAI)
