from agentforge.tool.llm import llm
import openai

class openai_llm(llm):
    """Concrete implementation of LLM for OpenAI models."""

    def __init__(self, tool_id: str, api_key: str, model: str = "gpt-4"):
        """
        Initialize the OpenAI LLM tool.

        Args:
            tool_id (str): Unique identifier for the tool.
            api_key (str): OpenAI API key for authentication.
            model (str): Model name to use (default: "gpt-4").
        """
        super().__init__(tool_id, model)
        self.api_key = api_key
        openai.api_key = self.api_key

    def execute(self, input_data: str) -> str:
        """
        Use the OpenAI LLM to process the input data and return the response.

        Args:
            input_data (str): The prompt or query for the LLM.

        Returns:
            str: The response generated by the LLM.
        """
        try:
            response = openai.ChatCompletion.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": input_data},
                ]
            )
            return response['choices'][0]['message']['content']
        except Exception as e:
            return f"Error: {str(e)}"

# Example usage
if __name__ == "__main__":
    openai_tool = openai_llm(tool_id="openai_gpt4", api_key="your-api-key")
    result = openai_tool.execute("What are the benefits of modular programming?")
    print(result)
    print(openai_tool)
